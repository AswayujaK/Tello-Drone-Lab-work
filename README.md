# Tello-Drone-Lab-work

Completed 6 labs related to Autonomous drone called Tello, as part of an academic project of the course Robotic Systems-II. The 6 labs are the following:

LAB 1- AUTONOMOUS FACE TRACKING DRONE:
  The drone will be able to identify faces in the captured footage in real time and then follows the user autonomously to keep the person in the video frame.
  
LAB 2 - OBJECT TRACKING DRONE: The drone will be able to identify different objects in the captured footage in real time based on the color (yellow tea cup in our implementation) and follows the object.

LAB 3 - CONTROLLING DRONE WITH BODY POSTURES: Identify the body postures in the frame and using KNN classify the pose and control the drone.

LAB 4 - CONTROLLING DRONE WITH HAND GESTURES: Identify the Hand Gestures in the frame and using KNN classify the gesture and control the drone.

LAB 5 - YELLO (YOLO + TELLO): The drone will be able to identify different objects in the captured footage in real time and then perform actions based on the detected object.

LAB 6 - COLLISION AVOIDANCE DRONE: The drone will be able to identify different objects in the captured footage in real time (human face in our implementation) follows the object and also makes sure the drone doesnâ€™t go too close to that object.



Reference to the repository used for this project is: https://github.com/crazysuryaa/Autonomous_Tello_Drone
